{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "from torch.optim import *\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "torch.manual_seed(7)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(7)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/beegfs/bva212/openmic-2018'\n",
    "OPENMIC = np.load(os.path.join(DATA_ROOT, 'openmic-2018.npz'))\n",
    "X, Y_true, Y_mask, sample_key = OPENMIC['X'], OPENMIC['Y_true'], OPENMIC['Y_mask'], OPENMIC['sample_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data = Y_mask.shape[0]\n",
    "idx_train = np.random.choice(len_data, int(len_data*0.7), replace=False)\n",
    "remain_set = set(np.arange(len_data))-set(idx_train)\n",
    "idx_test = np.random.choice(list(remain_set), int(len_data*0.1), replace=False)\n",
    "idx_val = list(remain_set-set(idx_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mask_train = Y_mask[idx_train]\n",
    "Y_mask_val = Y_mask[idx_val]\n",
    "Y_mask_test = Y_mask[idx_test]\n",
    "\n",
    "label_train = Y_true[idx_train]\n",
    "label_val = Y_true[idx_val]\n",
    "label_test = Y_true[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_train = np.sum(Y_mask_train, axis= 1)/20\n",
    "new_weights_train = weights_train.reshape(-1,1)*Y_mask_train\n",
    "weights_val = np.sum(Y_mask_val, axis= 1)/20\n",
    "new_weights_val = weights_val.reshape(-1,1)*Y_mask_val\n",
    "weights_test = np.sum(Y_mask_test, axis= 1)/20\n",
    "new_weights_test = weights_test.reshape(-1,1)*Y_mask_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrowOfTime(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, files, weights, label):\n",
    "        self.weights = weights\n",
    "        self.device = device\n",
    "        self.root_dir = root_dir\n",
    "        self.files = files\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        logscalogram = np.load(self.root_dir + self.files[idx]+'_cqt.npy')\n",
    "        weight = self.weights[idx]\n",
    "        label = self.label[idx]\n",
    "        return {'logscalogram': logscalogram[np.newaxis, :], 'label': label[np.newaxis, :], 'weight': weight[np.newaxis,:]}\n",
    "\n",
    "filenames = []\n",
    "root_dir = '/beegfs/bva212/openmic-2018/cqt_full/'\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def my_collate(batch):\n",
    "    data = np.concatenate([item['logscalogram'] for item in batch],axis=0)\n",
    "    data = np.expand_dims(data, axis = 1)\n",
    "    target = np.concatenate([item['label'] for item in batch],axis=0)\n",
    "    weight = np.concatenate([item['weight'] for item in batch],axis=0)\n",
    "    return [torch.from_numpy(data).float(), torch.from_numpy(target).float(), torch.from_numpy(weight).float()]\n",
    "\n",
    "Train_dataset = ArrowOfTime(root_dir, sample_key[idx_train], new_weights_train, label_train)\n",
    "Train_loader = torch.utils.data.DataLoader(dataset = Train_dataset, \n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              shuffle = True,\n",
    "                                          collate_fn = my_collate)\n",
    "\n",
    "Val_dataset = ArrowOfTime(root_dir, sample_key[idx_val], new_weights_val, label_val)\n",
    "Val_loader = torch.utils.data.DataLoader(dataset = Val_dataset, \n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              shuffle = True,\n",
    "                                        collate_fn = my_collate)\n",
    "\n",
    "Test_dataset = ArrowOfTime(root_dir, sample_key[idx_test], new_weights_test, label_test)\n",
    "Test_loader = torch.utils.data.DataLoader(dataset = Test_dataset, \n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              shuffle = True,\n",
    "                                        collate_fn = my_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Validation Accuracy:50.54, Training Acc: 50.24, Val Loss: 0.16454, Train Loss: 0.16415\n",
      "Epoch:2, Validation Accuracy:55.04, Training Acc: 54.86, Val Loss: 0.14236, Train Loss: 0.13992\n",
      "Epoch:3, Validation Accuracy:54.58, Training Acc: 54.42, Val Loss: 0.14563, Train Loss: 0.14233\n",
      "Epoch:4, Validation Accuracy:56.33, Training Acc: 55.97, Val Loss: 0.13798, Train Loss: 0.13428\n",
      "Epoch:5, Validation Accuracy:56.10, Training Acc: 56.61, Val Loss: 0.13824, Train Loss: 0.13367\n",
      "Epoch:6, Validation Accuracy:56.50, Training Acc: 57.20, Val Loss: 0.13435, Train Loss: 0.12715\n",
      "Epoch:7, Validation Accuracy:56.69, Training Acc: 57.34, Val Loss: 0.13268, Train Loss: 0.12653\n",
      "Epoch:8, Validation Accuracy:57.47, Training Acc: 58.00, Val Loss: 0.13044, Train Loss: 0.12293\n",
      "Epoch:9, Validation Accuracy:57.35, Training Acc: 57.91, Val Loss: 0.13462, Train Loss: 0.12544\n",
      "Epoch:10, Validation Accuracy:58.09, Training Acc: 58.76, Val Loss: 0.13047, Train Loss: 0.12202\n",
      "Epoch:11, Validation Accuracy:58.40, Training Acc: 59.53, Val Loss: 0.12956, Train Loss: 0.11790\n",
      "Epoch:12, Validation Accuracy:57.68, Training Acc: 58.86, Val Loss: 0.12781, Train Loss: 0.11780\n",
      "Epoch:13, Validation Accuracy:58.62, Training Acc: 59.48, Val Loss: 0.12821, Train Loss: 0.11703\n",
      "Epoch:14, Validation Accuracy:58.55, Training Acc: 59.81, Val Loss: 0.12727, Train Loss: 0.11462\n",
      "Epoch:15, Validation Accuracy:58.09, Training Acc: 59.52, Val Loss: 0.12885, Train Loss: 0.11460\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:16, Validation Accuracy:56.91, Training Acc: 58.17, Val Loss: 0.13321, Train Loss: 0.12007\n",
      "Epoch:17, Validation Accuracy:59.57, Training Acc: 61.31, Val Loss: 0.12296, Train Loss: 0.10489\n",
      "Epoch:18, Validation Accuracy:59.77, Training Acc: 61.58, Val Loss: 0.12139, Train Loss: 0.10333\n",
      "Epoch:19, Validation Accuracy:59.86, Training Acc: 61.66, Val Loss: 0.12192, Train Loss: 0.10241\n",
      "Epoch:20, Validation Accuracy:59.98, Training Acc: 61.66, Val Loss: 0.12160, Train Loss: 0.10210\n",
      "Epoch:21, Validation Accuracy:59.95, Training Acc: 61.76, Val Loss: 0.12200, Train Loss: 0.10164\n",
      "Epoch:22, Validation Accuracy:59.93, Training Acc: 61.93, Val Loss: 0.12108, Train Loss: 0.10101\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:23, Validation Accuracy:59.89, Training Acc: 62.06, Val Loss: 0.12152, Train Loss: 0.10039\n",
      "Epoch:24, Validation Accuracy:59.93, Training Acc: 62.04, Val Loss: 0.12129, Train Loss: 0.10012\n",
      "Epoch:25, Validation Accuracy:59.87, Training Acc: 62.16, Val Loss: 0.12125, Train Loss: 0.09979\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:26, Validation Accuracy:60.00, Training Acc: 62.08, Val Loss: 0.12079, Train Loss: 0.09971\n",
      "Epoch:27, Validation Accuracy:60.08, Training Acc: 62.10, Val Loss: 0.12129, Train Loss: 0.10000\n",
      "Epoch:28, Validation Accuracy:60.08, Training Acc: 62.14, Val Loss: 0.12084, Train Loss: 0.09981\n",
      "Epoch:29, Validation Accuracy:59.95, Training Acc: 62.08, Val Loss: 0.12121, Train Loss: 0.09971\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:30, Validation Accuracy:59.90, Training Acc: 62.03, Val Loss: 0.12124, Train Loss: 0.10029\n",
      "Epoch:31, Validation Accuracy:60.06, Training Acc: 62.11, Val Loss: 0.12126, Train Loss: 0.09962\n",
      "Epoch:32, Validation Accuracy:59.93, Training Acc: 62.10, Val Loss: 0.12130, Train Loss: 0.10037\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:33, Validation Accuracy:60.08, Training Acc: 62.12, Val Loss: 0.12132, Train Loss: 0.09974\n",
      "Epoch:34, Validation Accuracy:60.16, Training Acc: 62.09, Val Loss: 0.12109, Train Loss: 0.09982\n",
      "Epoch:35, Validation Accuracy:60.06, Training Acc: 62.16, Val Loss: 0.12078, Train Loss: 0.09981\n",
      "Epoch:36, Validation Accuracy:60.08, Training Acc: 62.10, Val Loss: 0.12093, Train Loss: 0.09983\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:37, Validation Accuracy:60.01, Training Acc: 62.10, Val Loss: 0.12104, Train Loss: 0.09975\n",
      "Epoch:38, Validation Accuracy:59.98, Training Acc: 62.11, Val Loss: 0.12120, Train Loss: 0.09987\n",
      "Epoch:39, Validation Accuracy:59.90, Training Acc: 62.05, Val Loss: 0.12137, Train Loss: 0.09993\n",
      "Epoch:40, Validation Accuracy:59.95, Training Acc: 62.11, Val Loss: 0.12093, Train Loss: 0.09990\n",
      "Epoch:41, Validation Accuracy:59.95, Training Acc: 62.09, Val Loss: 0.12119, Train Loss: 0.09979\n",
      "Epoch:42, Validation Accuracy:59.98, Training Acc: 62.09, Val Loss: 0.12106, Train Loss: 0.09998\n",
      "Epoch:43, Validation Accuracy:59.93, Training Acc: 62.09, Val Loss: 0.12136, Train Loss: 0.10039\n",
      "Epoch:44, Validation Accuracy:60.04, Training Acc: 62.08, Val Loss: 0.12118, Train Loss: 0.10009\n",
      "Epoch:45, Validation Accuracy:59.89, Training Acc: 62.03, Val Loss: 0.12219, Train Loss: 0.10047\n",
      "Epoch:46, Validation Accuracy:60.00, Training Acc: 62.13, Val Loss: 0.12116, Train Loss: 0.10000\n",
      "Epoch:47, Validation Accuracy:60.07, Training Acc: 62.18, Val Loss: 0.12050, Train Loss: 0.09969\n",
      "Epoch:48, Validation Accuracy:60.02, Training Acc: 62.10, Val Loss: 0.12137, Train Loss: 0.09967\n",
      "Epoch:49, Validation Accuracy:59.90, Training Acc: 62.05, Val Loss: 0.12122, Train Loss: 0.09981\n",
      "Epoch:50, Validation Accuracy:59.87, Training Acc: 62.14, Val Loss: 0.12111, Train Loss: 0.09987\n"
     ]
    }
   ],
   "source": [
    "class AudioConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_out):\n",
    "        super(AudioConvNet, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, stride=2)\n",
    "        self.pool1 = nn.AvgPool2d(2, stride=2)\n",
    "        self.pool2 = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(1, 64, 3, stride=2, padding=1)\n",
    "        self.cnn2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bat10 = nn.BatchNorm2d(64)\n",
    "        self.bat11 = nn.BatchNorm2d(64)\n",
    "\n",
    "\n",
    "        self.cnn3 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.cnn4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bat20 = nn.BatchNorm2d(128)\n",
    "        self.bat21 = nn.BatchNorm2d(128)\n",
    "\n",
    "\n",
    "        self.cnn5 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
    "        self.cnn6 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bat30 = nn.BatchNorm2d(256)\n",
    "        self.bat31 = nn.BatchNorm2d(256)\n",
    "\n",
    "\n",
    "        self.cnn7 = nn.Conv2d(256, 512, 3, stride=1, padding=1)\n",
    "        self.cnn8 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bat40 = nn.BatchNorm2d(512)\n",
    "        self.bat41 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.linear_final = nn.Linear(512, n_out)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        c = F.relu(self.bat10(self.cnn1(inp)))\n",
    "        c = F.relu(self.bat11(self.cnn2(c)))\n",
    "        c = self.pool(c)\n",
    "\n",
    "        c = F.relu(self.bat20(self.cnn3(c)))\n",
    "        c = F.relu(self.bat21(self.cnn4(c)))\n",
    "        c = self.pool1(c)\n",
    "\n",
    "        c = F.relu(self.bat30(self.cnn5(c)))\n",
    "        c = F.relu(self.bat31(self.cnn6(c)))\n",
    "        c = self.pool1(c)\n",
    "        \n",
    "        c = F.relu(self.bat40(self.cnn7(c)))\n",
    "        c = F.relu(self.bat41(self.cnn8(c)))\n",
    "        c = self.pool2(c)\n",
    "        \n",
    "        c = self.linear_final(c.reshape(c.shape[0],-1))\n",
    "\n",
    "        return c\n",
    "\n",
    "\n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    total_num = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for spectrogram, target, weight in loader:\n",
    "            spectrogram_batch, target_batch, weight_batch = spectrogram.to(device), target.to(device), weight.to(device)\n",
    "            outputs = model(spectrogram_batch)\n",
    "#             print(label_batch.shape)\n",
    "            predicted = (torch.sigmoid(outputs.data)>0.5).float()\n",
    "            loss = F.binary_cross_entropy_with_logits(outputs, target_batch,\n",
    "                                                  weight = weight_batch,\n",
    "                                                  reduction='sum')\n",
    "            total_loss += loss.item()\n",
    "            total += weight_batch.shape[0]\n",
    "\n",
    "            correct += ((weight_batch != 0).float()*(predicted.eq(target_batch.view_as(predicted)).float())).sum().item()\n",
    "            total_num += (weight_batch != 0).sum().item()\n",
    "    return (100 * correct / total_num), (total_loss/total)\n",
    "\n",
    "def train_model(train_loader, val_loader, model, optimizer, scheduler, num_epochs):\n",
    "    train_acc_list = []\n",
    "    train_loss_list = []\n",
    "    val_acc_list = []\n",
    "    val_loss_list = []\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for spectrogram, target, weight in train_loader:\n",
    "            model.train()\n",
    "            spectrogram_batch, target_batch, weight_batch = spectrogram.to(device), target.to(device), weight.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(spectrogram_batch)\n",
    "#             print(label_batch.shape)\n",
    "            loss = F.binary_cross_entropy_with_logits(outputs, target_batch,\n",
    "                                                  weight = weight_batch,\n",
    "                                                  reduction='mean')\n",
    "#             print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_acc, train_loss = test_model(train_loader, model)\n",
    "        val_acc, val_loss = test_model(val_loader, model)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state_dict = deepcopy(model.state_dict())\n",
    "        train_acc_list.append(train_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        val_loss_list.append(val_loss)\n",
    "        scheduler.step(val_acc)\n",
    "        print(\"Epoch:{}, Validation Accuracy:{:.2f}, Training Acc: {:.2f}, Val Loss: {:.5f}, Train Loss: {:.5f}\".format(epoch+1, val_acc, train_acc, val_loss, train_loss))\n",
    "    return train_acc_list, train_loss_list, val_acc_list, val_loss_list, best_model_state_dict\n",
    "\n",
    "model = AudioConvNet(20).to(device)\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 50 # number epoch to train\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True, threshold=0.03, threshold_mode='abs', cooldown=0, min_lr=0, eps=1e-08)\n",
    "train_acc_list, train_loss_list, val_acc_list, val_loss_list, best_model_state_dict = train_model(Train_loader, Val_loader, model, optimizer, scheduler, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
