{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "from torch.optim import *\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "random.seed(7)\n",
    "torch.cuda.manual_seed(7)\n",
    "torch.manual_seed(7)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(7)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/beegfs/bva212/openmic-2018'\n",
    "OPENMIC = np.load(os.path.join(DATA_ROOT, 'openmic-2018.npz'))\n",
    "X, Y_true, Y_mask, sample_key = OPENMIC['X'], OPENMIC['Y_true'], OPENMIC['Y_mask'], OPENMIC['sample_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data = Y_mask.shape[0]\n",
    "idx_train = np.random.choice(len_data, int(len_data*0.7), replace=False)\n",
    "remain_set = set(np.arange(len_data))-set(idx_train)\n",
    "idx_test = np.random.choice(list(remain_set), int(len_data*0.1), replace=False)\n",
    "idx_val = list(remain_set-set(idx_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mask_val = Y_mask[idx_val]\n",
    "Y_mask_test = Y_mask[idx_test]\n",
    "\n",
    "label_val = Y_true[idx_val]\n",
    "label_test = Y_true[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_val = np.sum(Y_mask_val, axis= 1)/20\n",
    "new_weights_val = weights_val.reshape(-1,1)*Y_mask_val\n",
    "weights_test = np.sum(Y_mask_test, axis= 1)/20\n",
    "new_weights_test = weights_test.reshape(-1,1)*Y_mask_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrowOfTime(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, files, weights, label):\n",
    "        self.weights = weights\n",
    "        self.device = device\n",
    "        self.root_dir = root_dir\n",
    "        self.files = files\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        logscalogram = (np.load(self.root_dir + self.files[idx]+'_cqt.npy') - -24.3633)/14.2659\n",
    "        len_cqt = logscalogram.shape[1]\n",
    "        rem = len_cqt % 3\n",
    "        logscalograms = np.split(logscalogram[:, :-rem], 3, axis = 1)\n",
    "        logscalograms = np.stack(logscalograms)\n",
    "        weight = self.weights[idx]\n",
    "        label = self.label[idx]\n",
    "        return {'logscalogram': logscalograms, 'label': label[np.newaxis, :], 'weight': weight[np.newaxis, :]}\n",
    "\n",
    "filenames = []\n",
    "root_dir = '/beegfs/bva212/openmic-2018/cqt_full/'\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def my_collate(batch):\n",
    "    data = np.stack([item['logscalogram'] for item in batch])\n",
    "    target = np.concatenate([item['label'] for item in batch],axis=0)\n",
    "    weight = np.concatenate([item['weight'] for item in batch],axis=0)\n",
    "    return [torch.from_numpy(data).float(), torch.from_numpy(target).float(), torch.from_numpy(weight).float()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class snet2_jigsaw(nn.Module):\n",
    "\n",
    "    def __init__(self, output_classes = 20):\n",
    "        '''\n",
    "        Create the 5 Conv Layer Sound Net network architecture as per the paper - https://arxiv.org/pdf/1610.09001.pdf\n",
    "        '''\n",
    "        super(snet2_jigsaw, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(nn.Conv2d(in_channels = 1, out_channels= 16, kernel_size = 5, stride = 2, padding = 5), \n",
    "                                nn.BatchNorm2d(num_features = 16), \n",
    "                                nn.ReLU(inplace = True),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, stride = 2, padding = 5),\n",
    "                                nn.BatchNorm2d(32),\n",
    "                                nn.ReLU(inplace = True),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5, padding = 5),\n",
    "                                nn.BatchNorm2d(64),\n",
    "                                nn.ReLU(inplace = True),\n",
    "                                nn.AvgPool2d(kernel_size = 3),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 4, padding = 4),\n",
    "                                nn.BatchNorm2d(128),\n",
    "                                nn.ReLU(inplace = True),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 4, padding = 4),\n",
    "                                nn.BatchNorm2d(256),\n",
    "                                nn.ReLU(inplace = True),\n",
    "                                nn.AvgPool2d(kernel_size = 3),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 2, padding = 3),\n",
    "                                nn.BatchNorm2d(512),\n",
    "                                nn.ReLU(inplace = True),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 512, out_channels = 1024, kernel_size = 3, stride = 2, padding = 3),\n",
    "                                nn.BatchNorm2d(1024),\n",
    "                                nn.ReLU(inplace = True),\n",
    "                                nn.AdaptiveAvgPool2d(output_size = 1)\n",
    "                                )\n",
    "        self.concat_mlp_layer = nn.Sequential(nn.Linear(3072, 2048),\n",
    "                                              nn.BatchNorm1d(num_features = 2048), \n",
    "                                              nn.ReLU(inplace = True),\n",
    "                                              \n",
    "                                              nn.Linear(2048, 1024),\n",
    "                                              nn.BatchNorm1d(num_features = 1024), \n",
    "                                              nn.ReLU(inplace = True),\n",
    "                                              \n",
    "                                              nn.Linear(1024, 256),\n",
    "                                              nn.BatchNorm1d(num_features = 256), \n",
    "                                              nn.ReLU(inplace = True),\n",
    "                                             )\n",
    "        self.mlp_layer = nn.Linear(256, output_classes)\n",
    "              \n",
    "    def forward(self, input):\n",
    "        conv_strips = []\n",
    "        n_strips = input.shape[1]\n",
    "        for strip in range(n_strips):\n",
    "            conv_strip = input[:,strip]\n",
    "            conv_strip = conv_strip.unsqueeze(1)\n",
    "            conv_strips.append(self.conv_layers(conv_strip))\n",
    "\n",
    "        concat_out=torch.cat(conv_strips,1)\n",
    "        out = self.concat_mlp_layer(concat_out.view(concat_out.shape[0], -1))\n",
    "        output = self.mlp_layer(out.view(out.shape[0], -1))\n",
    "        return output\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "        \n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    total_num = 0\n",
    "    actual_arr = []\n",
    "    predicted_arr = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for spectrogram, target, weight in loader:\n",
    "            spectrogram_batch, target_batch, weight_batch = spectrogram.to(device), target.to(device), weight.to(device)\n",
    "            outputs = model(spectrogram_batch)\n",
    "            loss = F.binary_cross_entropy_with_logits(outputs, target_batch,\n",
    "                                                  weight = weight_batch,\n",
    "                                                  reduction='sum')\n",
    "            predicted = (torch.sigmoid(outputs.data)>0.5).float()\n",
    "            \n",
    "            actual_arr.extend(target.view(1,-1).squeeze().numpy().astype(int).tolist())\n",
    "            predicted_arr.extend(predicted.view(1,-1).squeeze().cpu().numpy().astype(int).tolist())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total += weight_batch.shape[0]\n",
    "            \n",
    "            correct += ((weight_batch != 0).float()*(predicted.eq(target_batch.view_as(predicted)).float())).sum().item()\n",
    "            total_num += (weight_batch != 0).sum().item()\n",
    "        accuracy = (100 * correct / total_num)\n",
    "    return accuracy, f1_score(actual_arr, predicted_arr, average='micro'), total_loss/total\n",
    "\n",
    "def train_model(train_loader, val_loader, model, optimizer, scheduler, num_epochs):\n",
    "    train_acc_list = []\n",
    "    train_loss_list = []\n",
    "    val_acc_list = []\n",
    "    val_loss_list = []\n",
    "    train_f1_list = []\n",
    "    val_f1_list = []\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for spectrogram, target, weight in train_loader:\n",
    "            model.train()\n",
    "            spectrogram_batch, target_batch, weight_batch = spectrogram.to(device), target.to(device), weight.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(spectrogram_batch)\n",
    "            loss = F.binary_cross_entropy_with_logits(outputs, target_batch,\n",
    "                                                  weight = weight_batch,\n",
    "                                                  reduction='sum')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_acc, f1_score_train, train_loss = test_model(train_loader, model)\n",
    "        val_acc, f1_score_val, val_loss = test_model(val_loader, model)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state_dict = deepcopy(model.state_dict())\n",
    "        \n",
    "        train_acc_list.append(train_acc)\n",
    "        train_f1_list.append(f1_score_train)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_f1_list.append(f1_score_val)\n",
    "        val_acc_list.append(val_acc)\n",
    "        val_loss_list.append(val_loss)\n",
    "        \n",
    "        scheduler.step(val_acc)\n",
    "        print(\"Epoch:{}\".format(epoch+1))\n",
    "        print(\"Validation Accuracy:{:.2f}, Validation F1:{:.2f}, Val Loss: {:.5f}\".format(val_acc, f1_score_val, val_loss))\n",
    "        print(\"Training Acc: {:.2f}, Training F1:{:.2f}, Train Loss: {:.5f}\".format(train_acc, f1_score_train, train_loss))\n",
    "    return train_acc_list, train_loss_list, val_acc_list, val_loss_list, best_model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "sizes = [10, 50, 250, 500, 1000]\n",
    "\n",
    "Model_Data = pickle.load(open('List_indices_data_size_exp.pkl', 'rb'))\n",
    "\n",
    "Val_dataset = ArrowOfTime(root_dir, sample_key[idx_val], new_weights_val, label_val)\n",
    "Val_loader = torch.utils.data.DataLoader(dataset = Val_dataset, \n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              shuffle = True,\n",
    "                                        collate_fn = my_collate)\n",
    "\n",
    "Test_dataset = ArrowOfTime(root_dir, sample_key[idx_test], new_weights_test, label_test)\n",
    "Test_loader = torch.utils.data.DataLoader(dataset = Test_dataset, \n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              shuffle = True,\n",
    "                                        collate_fn = my_collate)\n",
    "\n",
    "\n",
    "for i in range(len(sizes)):\n",
    "    idx_train = Model_Data[i]\n",
    "    Y_mask_train = Y_mask[idx_train]\n",
    "    label_train = Y_true[idx_train]\n",
    "    weights_train = np.sum(Y_mask_train, axis= 1)/20\n",
    "    new_weights_train = weights_train.reshape(-1,1)*Y_mask_train\n",
    "    Train_dataset = ArrowOfTime(root_dir, sample_key[idx_train], new_weights_train, label_train)\n",
    "    Train_loader = torch.utils.data.DataLoader(dataset = Train_dataset, \n",
    "                                                  batch_size = BATCH_SIZE,\n",
    "                                                  shuffle = True,\n",
    "                                              collate_fn = my_collate)\n",
    "\n",
    "    \n",
    "    weights = torch.load('/beegfs/sc6957/capstone/models/20191106/snet2_jigsaw_large_best_model.pth')['modelStateDict']\n",
    "    model = snet2_jigsaw(2)\n",
    "    model.load_state_dict(weights)\n",
    "    model.mlp_layer = nn.Linear(256, 20)\n",
    "    model.to(device)\n",
    "    learning_rate = 10**(-5)\n",
    "    num_epochs = 50 # number epoch to train\n",
    "\n",
    "    optimizer = torch.optim.Adam([param for param in model.parameters() if param.requires_grad == True], lr=learning_rate, weight_decay = 0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True, threshold=0.03,\n",
    "                                                           threshold_mode='abs', cooldown=0, min_lr=0, eps=1e-08)\n",
    "\n",
    "    train_acc_list, train_loss_list, val_acc_list, val_loss_list, best_model_state_dict = train_model(Train_loader, Val_loader, model, optimizer, scheduler, num_epochs)\n",
    "    results_dict[sizes[i]] = {\n",
    "        'train_acc_list':train_acc_list,\n",
    "        'train_loss_list': train_loss_list,\n",
    "        'val_acc_list': val_acc_list,\n",
    "        'val_loss_list': val_loss_list,\n",
    "        'best_model_state_dict': best_model_state_dict\n",
    "    }\n",
    "pickle.dump(results_dict, open('Size_Exp_Jigsaw_Wt_Results.pkl'.format(sizes[i]),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n",
      "Validation Accuracy:34.82, Validation F1:0.56, Val Loss: 0.19598\n",
      "Training Acc: 36.71, Training F1:0.56, Train Loss: 0.21569\n",
      "Epoch:2\n",
      "Validation Accuracy:38.21, Validation F1:0.51, Val Loss: 0.19323\n",
      "Training Acc: 55.63, Training F1:0.54, Train Loss: 0.19107\n",
      "Epoch:3\n",
      "Validation Accuracy:40.62, Validation F1:0.51, Val Loss: 0.19150\n",
      "Training Acc: 62.39, Training F1:0.53, Train Loss: 0.14832\n",
      "Epoch:4\n",
      "Validation Accuracy:40.61, Validation F1:0.49, Val Loss: 0.19145\n",
      "Training Acc: 64.19, Training F1:0.51, Train Loss: 0.13654\n",
      "Epoch:5\n",
      "Validation Accuracy:41.90, Validation F1:0.51, Val Loss: 0.19135\n",
      "Training Acc: 64.64, Training F1:0.53, Train Loss: 0.12195\n",
      "Epoch:6\n",
      "Validation Accuracy:42.24, Validation F1:0.52, Val Loss: 0.19032\n",
      "Training Acc: 65.54, Training F1:0.53, Train Loss: 0.11523\n",
      "Epoch:7\n",
      "Validation Accuracy:42.09, Validation F1:0.51, Val Loss: 0.18926\n",
      "Training Acc: 66.22, Training F1:0.53, Train Loss: 0.10914\n",
      "Epoch:8\n",
      "Validation Accuracy:41.57, Validation F1:0.47, Val Loss: 0.19079\n",
      "Training Acc: 66.67, Training F1:0.49, Train Loss: 0.10491\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:9\n",
      "Validation Accuracy:42.21, Validation F1:0.51, Val Loss: 0.19079\n",
      "Training Acc: 66.44, Training F1:0.52, Train Loss: 0.09823\n",
      "Epoch:10\n",
      "Validation Accuracy:41.62, Validation F1:0.49, Val Loss: 0.19047\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09804\n",
      "Epoch:11\n",
      "Validation Accuracy:42.51, Validation F1:0.51, Val Loss: 0.18735\n",
      "Training Acc: 66.44, Training F1:0.53, Train Loss: 0.10311\n",
      "Epoch:12\n",
      "Validation Accuracy:41.61, Validation F1:0.50, Val Loss: 0.19073\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09614\n",
      "Epoch:13\n",
      "Validation Accuracy:41.69, Validation F1:0.49, Val Loss: 0.19052\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09588\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:14\n",
      "Validation Accuracy:41.13, Validation F1:0.48, Val Loss: 0.19170\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09686\n",
      "Epoch:15\n",
      "Validation Accuracy:42.03, Validation F1:0.51, Val Loss: 0.18962\n",
      "Training Acc: 66.67, Training F1:0.53, Train Loss: 0.09549\n",
      "Epoch:16\n",
      "Validation Accuracy:42.22, Validation F1:0.48, Val Loss: 0.18996\n",
      "Training Acc: 66.67, Training F1:0.49, Train Loss: 0.10012\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:17\n",
      "Validation Accuracy:42.12, Validation F1:0.49, Val Loss: 0.18959\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09806\n",
      "Epoch:18\n",
      "Validation Accuracy:42.41, Validation F1:0.50, Val Loss: 0.18916\n",
      "Training Acc: 66.67, Training F1:0.52, Train Loss: 0.09762\n",
      "Epoch:19\n",
      "Validation Accuracy:42.53, Validation F1:0.51, Val Loss: 0.18925\n",
      "Training Acc: 66.67, Training F1:0.53, Train Loss: 0.09421\n",
      "Epoch:20\n",
      "Validation Accuracy:42.37, Validation F1:0.48, Val Loss: 0.18847\n",
      "Training Acc: 65.99, Training F1:0.51, Train Loss: 0.10306\n",
      "Epoch:21\n",
      "Validation Accuracy:42.06, Validation F1:0.49, Val Loss: 0.18955\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09593\n",
      "Epoch:22\n",
      "Validation Accuracy:42.91, Validation F1:0.51, Val Loss: 0.18712\n",
      "Training Acc: 66.44, Training F1:0.53, Train Loss: 0.09640\n",
      "Epoch:23\n",
      "Validation Accuracy:42.43, Validation F1:0.50, Val Loss: 0.18960\n",
      "Training Acc: 66.67, Training F1:0.52, Train Loss: 0.09434\n",
      "Epoch:24\n",
      "Validation Accuracy:42.50, Validation F1:0.50, Val Loss: 0.18886\n",
      "Training Acc: 66.44, Training F1:0.52, Train Loss: 0.09543\n",
      "Epoch:25\n",
      "Validation Accuracy:42.26, Validation F1:0.50, Val Loss: 0.18896\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09508\n",
      "Epoch:26\n",
      "Validation Accuracy:42.31, Validation F1:0.50, Val Loss: 0.19049\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09455\n",
      "Epoch:27\n",
      "Validation Accuracy:41.65, Validation F1:0.50, Val Loss: 0.19220\n",
      "Training Acc: 66.67, Training F1:0.52, Train Loss: 0.09412\n",
      "Epoch:28\n",
      "Validation Accuracy:41.69, Validation F1:0.48, Val Loss: 0.19044\n",
      "Training Acc: 66.67, Training F1:0.50, Train Loss: 0.09604\n",
      "Epoch:29\n",
      "Validation Accuracy:41.78, Validation F1:0.50, Val Loss: 0.19220\n",
      "Training Acc: 66.44, Training F1:0.52, Train Loss: 0.09344\n",
      "Epoch:30\n",
      "Validation Accuracy:42.10, Validation F1:0.48, Val Loss: 0.18887\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.10022\n",
      "Epoch:31\n",
      "Validation Accuracy:42.82, Validation F1:0.50, Val Loss: 0.18781\n",
      "Training Acc: 66.67, Training F1:0.52, Train Loss: 0.09617\n",
      "Epoch:32\n",
      "Validation Accuracy:41.95, Validation F1:0.51, Val Loss: 0.19137\n",
      "Training Acc: 66.67, Training F1:0.53, Train Loss: 0.09210\n",
      "Epoch:33\n",
      "Validation Accuracy:42.03, Validation F1:0.49, Val Loss: 0.19043\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09370\n",
      "Epoch:34\n",
      "Validation Accuracy:41.78, Validation F1:0.50, Val Loss: 0.19124\n",
      "Training Acc: 66.67, Training F1:0.52, Train Loss: 0.09332\n",
      "Epoch:35\n",
      "Validation Accuracy:42.41, Validation F1:0.51, Val Loss: 0.18941\n",
      "Training Acc: 66.44, Training F1:0.53, Train Loss: 0.09238\n",
      "Epoch:36\n",
      "Validation Accuracy:42.73, Validation F1:0.52, Val Loss: 0.18879\n",
      "Training Acc: 66.44, Training F1:0.53, Train Loss: 0.09250\n",
      "Epoch:37\n",
      "Validation Accuracy:41.67, Validation F1:0.48, Val Loss: 0.19043\n",
      "Training Acc: 66.67, Training F1:0.50, Train Loss: 0.09807\n",
      "Epoch:38\n",
      "Validation Accuracy:41.52, Validation F1:0.50, Val Loss: 0.19137\n",
      "Training Acc: 66.44, Training F1:0.51, Train Loss: 0.09575\n",
      "Epoch:39\n",
      "Validation Accuracy:41.55, Validation F1:0.49, Val Loss: 0.19106\n",
      "Training Acc: 66.67, Training F1:0.50, Train Loss: 0.09466\n",
      "Epoch:40\n",
      "Validation Accuracy:42.32, Validation F1:0.50, Val Loss: 0.18748\n",
      "Training Acc: 66.44, Training F1:0.52, Train Loss: 0.10075\n",
      "Epoch:41\n",
      "Validation Accuracy:42.51, Validation F1:0.52, Val Loss: 0.19070\n",
      "Training Acc: 66.44, Training F1:0.53, Train Loss: 0.09207\n",
      "Epoch:42\n",
      "Validation Accuracy:42.60, Validation F1:0.50, Val Loss: 0.18808\n",
      "Training Acc: 66.67, Training F1:0.52, Train Loss: 0.09869\n",
      "Epoch:43\n",
      "Validation Accuracy:42.30, Validation F1:0.50, Val Loss: 0.18966\n",
      "Training Acc: 66.67, Training F1:0.52, Train Loss: 0.09348\n",
      "Epoch:44\n",
      "Validation Accuracy:41.96, Validation F1:0.50, Val Loss: 0.19047\n",
      "Training Acc: 66.67, Training F1:0.52, Train Loss: 0.09449\n",
      "Epoch:45\n",
      "Validation Accuracy:42.24, Validation F1:0.50, Val Loss: 0.18904\n",
      "Training Acc: 66.67, Training F1:0.52, Train Loss: 0.09477\n",
      "Epoch:46\n",
      "Validation Accuracy:42.33, Validation F1:0.51, Val Loss: 0.18799\n",
      "Training Acc: 66.67, Training F1:0.52, Train Loss: 0.09586\n",
      "Epoch:47\n",
      "Validation Accuracy:41.62, Validation F1:0.49, Val Loss: 0.19058\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09558\n",
      "Epoch:48\n",
      "Validation Accuracy:41.24, Validation F1:0.47, Val Loss: 0.19137\n",
      "Training Acc: 66.67, Training F1:0.49, Train Loss: 0.09897\n",
      "Epoch:49\n",
      "Validation Accuracy:41.66, Validation F1:0.47, Val Loss: 0.19019\n",
      "Training Acc: 66.67, Training F1:0.49, Train Loss: 0.10131\n",
      "Epoch:50\n",
      "Validation Accuracy:41.61, Validation F1:0.48, Val Loss: 0.19101\n",
      "Training Acc: 66.67, Training F1:0.51, Train Loss: 0.09820\n",
      "Epoch:1\n",
      "Validation Accuracy:42.13, Validation F1:0.51, Val Loss: 0.18744\n",
      "Training Acc: 51.69, Training F1:0.51, Train Loss: 0.16646\n",
      "Epoch:2\n",
      "Validation Accuracy:44.31, Validation F1:0.52, Val Loss: 0.18141\n",
      "Training Acc: 58.12, Training F1:0.53, Train Loss: 0.14961\n",
      "Epoch:3\n",
      "Validation Accuracy:46.18, Validation F1:0.54, Val Loss: 0.17678\n",
      "Training Acc: 61.69, Training F1:0.55, Train Loss: 0.13693\n",
      "Epoch:4\n",
      "Validation Accuracy:47.17, Validation F1:0.55, Val Loss: 0.17404\n",
      "Training Acc: 63.14, Training F1:0.56, Train Loss: 0.12915\n",
      "Epoch:5\n",
      "Validation Accuracy:46.63, Validation F1:0.55, Val Loss: 0.17586\n",
      "Training Acc: 63.29, Training F1:0.56, Train Loss: 0.12149\n",
      "Epoch:6\n",
      "Validation Accuracy:48.49, Validation F1:0.56, Val Loss: 0.17196\n",
      "Training Acc: 65.80, Training F1:0.57, Train Loss: 0.11342\n",
      "Epoch:7\n",
      "Validation Accuracy:48.21, Validation F1:0.56, Val Loss: 0.17192\n",
      "Training Acc: 66.86, Training F1:0.57, Train Loss: 0.10426\n",
      "Epoch:8\n",
      "Validation Accuracy:48.96, Validation F1:0.55, Val Loss: 0.16966\n",
      "Training Acc: 67.78, Training F1:0.56, Train Loss: 0.09923\n",
      "Epoch:9\n",
      "Validation Accuracy:51.22, Validation F1:0.61, Val Loss: 0.16470\n",
      "Training Acc: 68.45, Training F1:0.62, Train Loss: 0.09200\n",
      "Epoch:10\n",
      "Validation Accuracy:50.05, Validation F1:0.60, Val Loss: 0.16581\n",
      "Training Acc: 68.70, Training F1:0.61, Train Loss: 0.09107\n",
      "Epoch:11\n",
      "Validation Accuracy:51.02, Validation F1:0.62, Val Loss: 0.16506\n",
      "Training Acc: 68.89, Training F1:0.62, Train Loss: 0.08486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:12\n",
      "Validation Accuracy:50.30, Validation F1:0.62, Val Loss: 0.16599\n",
      "Training Acc: 69.42, Training F1:0.62, Train Loss: 0.07756\n",
      "Epoch:13\n",
      "Validation Accuracy:51.15, Validation F1:0.63, Val Loss: 0.16397\n",
      "Training Acc: 69.57, Training F1:0.63, Train Loss: 0.07648\n",
      "Epoch:14\n",
      "Validation Accuracy:51.24, Validation F1:0.63, Val Loss: 0.16301\n",
      "Training Acc: 69.66, Training F1:0.63, Train Loss: 0.07471\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:15\n",
      "Validation Accuracy:51.03, Validation F1:0.63, Val Loss: 0.16364\n",
      "Training Acc: 69.57, Training F1:0.63, Train Loss: 0.07423\n",
      "Epoch:16\n",
      "Validation Accuracy:50.55, Validation F1:0.59, Val Loss: 0.16611\n",
      "Training Acc: 69.61, Training F1:0.60, Train Loss: 0.07684\n",
      "Epoch:17\n",
      "Validation Accuracy:50.78, Validation F1:0.61, Val Loss: 0.16458\n",
      "Training Acc: 69.66, Training F1:0.61, Train Loss: 0.07290\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:18\n",
      "Validation Accuracy:51.25, Validation F1:0.62, Val Loss: 0.16359\n",
      "Training Acc: 69.61, Training F1:0.63, Train Loss: 0.07474\n",
      "Epoch:19\n",
      "Validation Accuracy:51.03, Validation F1:0.62, Val Loss: 0.16401\n",
      "Training Acc: 69.61, Training F1:0.62, Train Loss: 0.07321\n",
      "Epoch:20\n",
      "Validation Accuracy:50.72, Validation F1:0.62, Val Loss: 0.16439\n",
      "Training Acc: 69.61, Training F1:0.62, Train Loss: 0.07447\n",
      "Epoch:21\n",
      "Validation Accuracy:50.75, Validation F1:0.62, Val Loss: 0.16406\n",
      "Training Acc: 69.61, Training F1:0.62, Train Loss: 0.07469\n",
      "Epoch:22\n",
      "Validation Accuracy:51.38, Validation F1:0.62, Val Loss: 0.16362\n",
      "Training Acc: 69.57, Training F1:0.62, Train Loss: 0.07512\n",
      "Epoch:23\n",
      "Validation Accuracy:50.27, Validation F1:0.59, Val Loss: 0.16530\n",
      "Training Acc: 69.57, Training F1:0.60, Train Loss: 0.07425\n",
      "Epoch:24\n",
      "Validation Accuracy:50.71, Validation F1:0.60, Val Loss: 0.16604\n",
      "Training Acc: 69.37, Training F1:0.60, Train Loss: 0.07764\n",
      "Epoch:25\n",
      "Validation Accuracy:50.59, Validation F1:0.62, Val Loss: 0.16360\n",
      "Training Acc: 69.61, Training F1:0.62, Train Loss: 0.07107\n",
      "Epoch:26\n",
      "Validation Accuracy:50.86, Validation F1:0.62, Val Loss: 0.16334\n",
      "Training Acc: 69.66, Training F1:0.62, Train Loss: 0.07254\n",
      "Epoch:27\n",
      "Validation Accuracy:50.72, Validation F1:0.62, Val Loss: 0.16499\n",
      "Training Acc: 69.61, Training F1:0.62, Train Loss: 0.07352\n",
      "Epoch:28\n",
      "Validation Accuracy:50.43, Validation F1:0.60, Val Loss: 0.16631\n",
      "Training Acc: 69.57, Training F1:0.60, Train Loss: 0.07529\n",
      "Epoch:29\n",
      "Validation Accuracy:50.95, Validation F1:0.61, Val Loss: 0.16336\n",
      "Training Acc: 69.71, Training F1:0.61, Train Loss: 0.07316\n",
      "Epoch:30\n",
      "Validation Accuracy:50.97, Validation F1:0.61, Val Loss: 0.16463\n",
      "Training Acc: 69.71, Training F1:0.61, Train Loss: 0.07568\n",
      "Epoch:31\n",
      "Validation Accuracy:50.73, Validation F1:0.61, Val Loss: 0.16494\n",
      "Training Acc: 69.57, Training F1:0.61, Train Loss: 0.07464\n",
      "Epoch:32\n",
      "Validation Accuracy:51.27, Validation F1:0.64, Val Loss: 0.16295\n",
      "Training Acc: 69.61, Training F1:0.64, Train Loss: 0.07346\n",
      "Epoch:33\n",
      "Validation Accuracy:50.34, Validation F1:0.61, Val Loss: 0.16494\n",
      "Training Acc: 69.57, Training F1:0.61, Train Loss: 0.07501\n",
      "Epoch:34\n",
      "Validation Accuracy:50.67, Validation F1:0.61, Val Loss: 0.16516\n",
      "Training Acc: 69.57, Training F1:0.61, Train Loss: 0.07267\n",
      "Epoch:35\n",
      "Validation Accuracy:50.37, Validation F1:0.61, Val Loss: 0.16549\n",
      "Training Acc: 69.57, Training F1:0.61, Train Loss: 0.07639\n",
      "Epoch:36\n",
      "Validation Accuracy:51.33, Validation F1:0.62, Val Loss: 0.16420\n",
      "Training Acc: 69.66, Training F1:0.62, Train Loss: 0.07366\n",
      "Epoch:37\n",
      "Validation Accuracy:50.92, Validation F1:0.61, Val Loss: 0.16486\n",
      "Training Acc: 69.71, Training F1:0.61, Train Loss: 0.07303\n",
      "Epoch:38\n",
      "Validation Accuracy:50.84, Validation F1:0.63, Val Loss: 0.16344\n",
      "Training Acc: 69.71, Training F1:0.63, Train Loss: 0.07471\n",
      "Epoch:39\n",
      "Validation Accuracy:51.10, Validation F1:0.61, Val Loss: 0.16375\n",
      "Training Acc: 69.66, Training F1:0.62, Train Loss: 0.07561\n",
      "Epoch:40\n",
      "Validation Accuracy:51.08, Validation F1:0.61, Val Loss: 0.16430\n",
      "Training Acc: 69.71, Training F1:0.62, Train Loss: 0.07453\n",
      "Epoch:41\n",
      "Validation Accuracy:50.75, Validation F1:0.62, Val Loss: 0.16379\n",
      "Training Acc: 69.57, Training F1:0.62, Train Loss: 0.07366\n",
      "Epoch:42\n",
      "Validation Accuracy:51.01, Validation F1:0.62, Val Loss: 0.16397\n",
      "Training Acc: 69.66, Training F1:0.62, Train Loss: 0.07334\n",
      "Epoch:43\n",
      "Validation Accuracy:51.54, Validation F1:0.63, Val Loss: 0.16176\n",
      "Training Acc: 69.37, Training F1:0.63, Train Loss: 0.07496\n",
      "Epoch:44\n",
      "Validation Accuracy:51.03, Validation F1:0.62, Val Loss: 0.16460\n",
      "Training Acc: 69.57, Training F1:0.62, Train Loss: 0.07368\n",
      "Epoch:45\n",
      "Validation Accuracy:51.33, Validation F1:0.62, Val Loss: 0.16295\n",
      "Training Acc: 69.57, Training F1:0.63, Train Loss: 0.07247\n",
      "Epoch:46\n",
      "Validation Accuracy:50.92, Validation F1:0.61, Val Loss: 0.16383\n",
      "Training Acc: 69.66, Training F1:0.62, Train Loss: 0.07482\n",
      "Epoch:47\n",
      "Validation Accuracy:50.96, Validation F1:0.63, Val Loss: 0.16293\n",
      "Training Acc: 69.66, Training F1:0.63, Train Loss: 0.07330\n",
      "Epoch:48\n",
      "Validation Accuracy:50.86, Validation F1:0.64, Val Loss: 0.16354\n",
      "Training Acc: 69.61, Training F1:0.64, Train Loss: 0.07366\n",
      "Epoch:49\n",
      "Validation Accuracy:50.85, Validation F1:0.61, Val Loss: 0.16488\n",
      "Training Acc: 69.71, Training F1:0.62, Train Loss: 0.07537\n",
      "Epoch:50\n",
      "Validation Accuracy:51.73, Validation F1:0.64, Val Loss: 0.16203\n",
      "Training Acc: 69.57, Training F1:0.64, Train Loss: 0.07107\n",
      "Epoch:1\n",
      "Validation Accuracy:48.09, Validation F1:0.53, Val Loss: 0.17328\n",
      "Training Acc: 52.40, Training F1:0.53, Train Loss: 0.16568\n",
      "Epoch:2\n",
      "Validation Accuracy:52.30, Validation F1:0.58, Val Loss: 0.16168\n",
      "Training Acc: 56.95, Training F1:0.58, Train Loss: 0.14931\n",
      "Epoch:3\n",
      "Validation Accuracy:53.70, Validation F1:0.62, Val Loss: 0.15664\n",
      "Training Acc: 59.41, Training F1:0.62, Train Loss: 0.13966\n",
      "Epoch:4\n",
      "Validation Accuracy:55.09, Validation F1:0.65, Val Loss: 0.14963\n",
      "Training Acc: 60.56, Training F1:0.65, Train Loss: 0.12992\n",
      "Epoch:5\n",
      "Validation Accuracy:55.97, Validation F1:0.66, Val Loss: 0.14718\n",
      "Training Acc: 62.46, Training F1:0.66, Train Loss: 0.12143\n",
      "Epoch:6\n",
      "Validation Accuracy:56.76, Validation F1:0.68, Val Loss: 0.14179\n",
      "Training Acc: 64.24, Training F1:0.68, Train Loss: 0.11040\n",
      "Epoch:7\n",
      "Validation Accuracy:56.88, Validation F1:0.69, Val Loss: 0.14235\n",
      "Training Acc: 65.30, Training F1:0.70, Train Loss: 0.10447\n",
      "Epoch:8\n",
      "Validation Accuracy:56.98, Validation F1:0.71, Val Loss: 0.13724\n",
      "Training Acc: 65.95, Training F1:0.71, Train Loss: 0.09721\n",
      "Epoch:9\n",
      "Validation Accuracy:57.63, Validation F1:0.71, Val Loss: 0.13516\n",
      "Training Acc: 66.91, Training F1:0.72, Train Loss: 0.08652\n",
      "Epoch:10\n",
      "Validation Accuracy:57.75, Validation F1:0.71, Val Loss: 0.13372\n",
      "Training Acc: 67.73, Training F1:0.72, Train Loss: 0.08070\n",
      "Epoch:11\n",
      "Validation Accuracy:57.78, Validation F1:0.70, Val Loss: 0.13374\n",
      "Training Acc: 68.28, Training F1:0.71, Train Loss: 0.07472\n",
      "Epoch:12\n",
      "Validation Accuracy:57.90, Validation F1:0.71, Val Loss: 0.13242\n",
      "Training Acc: 68.66, Training F1:0.72, Train Loss: 0.06969\n",
      "Epoch:13\n",
      "Validation Accuracy:57.92, Validation F1:0.72, Val Loss: 0.13181\n",
      "Training Acc: 68.84, Training F1:0.73, Train Loss: 0.06454\n",
      "Epoch:14\n",
      "Validation Accuracy:57.38, Validation F1:0.72, Val Loss: 0.13051\n",
      "Training Acc: 69.11, Training F1:0.73, Train Loss: 0.05878\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:15\n",
      "Validation Accuracy:57.75, Validation F1:0.73, Val Loss: 0.12911\n",
      "Training Acc: 69.31, Training F1:0.74, Train Loss: 0.05650\n",
      "Epoch:16\n",
      "Validation Accuracy:57.67, Validation F1:0.73, Val Loss: 0.12988\n",
      "Training Acc: 69.37, Training F1:0.74, Train Loss: 0.05430\n",
      "Epoch:17\n",
      "Validation Accuracy:57.76, Validation F1:0.72, Val Loss: 0.13016\n",
      "Training Acc: 69.39, Training F1:0.74, Train Loss: 0.05352\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:18\n",
      "Validation Accuracy:57.47, Validation F1:0.72, Val Loss: 0.13101\n",
      "Training Acc: 69.39, Training F1:0.74, Train Loss: 0.05417\n",
      "Epoch:19\n",
      "Validation Accuracy:57.33, Validation F1:0.71, Val Loss: 0.13206\n",
      "Training Acc: 69.38, Training F1:0.72, Train Loss: 0.05495\n",
      "Epoch:20\n",
      "Validation Accuracy:57.29, Validation F1:0.70, Val Loss: 0.13193\n",
      "Training Acc: 69.38, Training F1:0.71, Train Loss: 0.05440\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:21\n",
      "Validation Accuracy:57.82, Validation F1:0.73, Val Loss: 0.12831\n",
      "Training Acc: 69.41, Training F1:0.74, Train Loss: 0.05114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:22\n",
      "Validation Accuracy:57.50, Validation F1:0.71, Val Loss: 0.13033\n",
      "Training Acc: 69.39, Training F1:0.72, Train Loss: 0.05326\n",
      "Epoch:23\n",
      "Validation Accuracy:57.52, Validation F1:0.71, Val Loss: 0.12947\n",
      "Training Acc: 69.39, Training F1:0.73, Train Loss: 0.05307\n",
      "Epoch:24\n",
      "Validation Accuracy:57.64, Validation F1:0.73, Val Loss: 0.12943\n",
      "Training Acc: 69.39, Training F1:0.74, Train Loss: 0.05289\n",
      "Epoch:25\n",
      "Validation Accuracy:57.58, Validation F1:0.73, Val Loss: 0.12791\n",
      "Training Acc: 69.39, Training F1:0.74, Train Loss: 0.05264\n",
      "Epoch:26\n",
      "Validation Accuracy:57.57, Validation F1:0.73, Val Loss: 0.12868\n",
      "Training Acc: 69.37, Training F1:0.74, Train Loss: 0.05258\n",
      "Epoch:27\n",
      "Validation Accuracy:57.15, Validation F1:0.71, Val Loss: 0.13303\n",
      "Training Acc: 69.39, Training F1:0.72, Train Loss: 0.05505\n",
      "Epoch:28\n",
      "Validation Accuracy:57.26, Validation F1:0.72, Val Loss: 0.13195\n",
      "Training Acc: 69.38, Training F1:0.73, Train Loss: 0.05438\n",
      "Epoch:29\n",
      "Validation Accuracy:57.82, Validation F1:0.73, Val Loss: 0.12854\n",
      "Training Acc: 69.40, Training F1:0.74, Train Loss: 0.05230\n",
      "Epoch:30\n",
      "Validation Accuracy:57.37, Validation F1:0.70, Val Loss: 0.13223\n",
      "Training Acc: 69.39, Training F1:0.71, Train Loss: 0.05436\n",
      "Epoch:31\n",
      "Validation Accuracy:57.69, Validation F1:0.72, Val Loss: 0.12975\n",
      "Training Acc: 69.39, Training F1:0.73, Train Loss: 0.05330\n",
      "Epoch:32\n",
      "Validation Accuracy:57.46, Validation F1:0.71, Val Loss: 0.12975\n",
      "Training Acc: 69.37, Training F1:0.72, Train Loss: 0.05334\n",
      "Epoch:33\n",
      "Validation Accuracy:57.69, Validation F1:0.74, Val Loss: 0.12794\n",
      "Training Acc: 69.38, Training F1:0.75, Train Loss: 0.05145\n",
      "Epoch:34\n",
      "Validation Accuracy:57.56, Validation F1:0.72, Val Loss: 0.13029\n",
      "Training Acc: 69.38, Training F1:0.74, Train Loss: 0.05321\n",
      "Epoch:35\n",
      "Validation Accuracy:57.16, Validation F1:0.70, Val Loss: 0.13163\n",
      "Training Acc: 69.39, Training F1:0.72, Train Loss: 0.05277\n",
      "Epoch:36\n",
      "Validation Accuracy:57.12, Validation F1:0.71, Val Loss: 0.13219\n",
      "Training Acc: 69.37, Training F1:0.72, Train Loss: 0.05336\n",
      "Epoch:37\n",
      "Validation Accuracy:57.62, Validation F1:0.73, Val Loss: 0.12818\n",
      "Training Acc: 69.40, Training F1:0.75, Train Loss: 0.05288\n",
      "Epoch:38\n",
      "Validation Accuracy:57.34, Validation F1:0.72, Val Loss: 0.13142\n",
      "Training Acc: 69.37, Training F1:0.73, Train Loss: 0.05373\n",
      "Epoch:39\n",
      "Validation Accuracy:57.44, Validation F1:0.72, Val Loss: 0.13139\n",
      "Training Acc: 69.39, Training F1:0.73, Train Loss: 0.05396\n",
      "Epoch:40\n",
      "Validation Accuracy:57.27, Validation F1:0.72, Val Loss: 0.13069\n",
      "Training Acc: 69.36, Training F1:0.73, Train Loss: 0.05409\n",
      "Epoch:41\n",
      "Validation Accuracy:57.85, Validation F1:0.73, Val Loss: 0.12916\n",
      "Training Acc: 69.40, Training F1:0.74, Train Loss: 0.05207\n",
      "Epoch:42\n",
      "Validation Accuracy:57.52, Validation F1:0.71, Val Loss: 0.12993\n",
      "Training Acc: 69.39, Training F1:0.73, Train Loss: 0.05333\n",
      "Epoch:43\n",
      "Validation Accuracy:57.33, Validation F1:0.72, Val Loss: 0.12986\n",
      "Training Acc: 69.38, Training F1:0.73, Train Loss: 0.05244\n",
      "Epoch:44\n",
      "Validation Accuracy:57.63, Validation F1:0.73, Val Loss: 0.12837\n",
      "Training Acc: 69.42, Training F1:0.74, Train Loss: 0.05210\n",
      "Epoch:45\n",
      "Validation Accuracy:57.29, Validation F1:0.72, Val Loss: 0.12994\n",
      "Training Acc: 69.39, Training F1:0.73, Train Loss: 0.05257\n",
      "Epoch:46\n",
      "Validation Accuracy:57.45, Validation F1:0.71, Val Loss: 0.13034\n",
      "Training Acc: 69.36, Training F1:0.72, Train Loss: 0.05297\n",
      "Epoch:47\n",
      "Validation Accuracy:57.79, Validation F1:0.72, Val Loss: 0.12873\n",
      "Training Acc: 69.39, Training F1:0.74, Train Loss: 0.05254\n",
      "Epoch:48\n",
      "Validation Accuracy:57.53, Validation F1:0.73, Val Loss: 0.12972\n",
      "Training Acc: 69.40, Training F1:0.74, Train Loss: 0.05257\n",
      "Epoch:49\n",
      "Validation Accuracy:57.29, Validation F1:0.71, Val Loss: 0.13069\n",
      "Training Acc: 69.38, Training F1:0.72, Train Loss: 0.05326\n",
      "Epoch:50\n",
      "Validation Accuracy:57.11, Validation F1:0.70, Val Loss: 0.13271\n",
      "Training Acc: 69.38, Training F1:0.71, Train Loss: 0.05384\n",
      "Epoch:1\n",
      "Validation Accuracy:52.23, Validation F1:0.62, Val Loss: 0.16174\n",
      "Training Acc: 54.28, Training F1:0.62, Train Loss: 0.15751\n",
      "Epoch:2\n",
      "Validation Accuracy:55.34, Validation F1:0.67, Val Loss: 0.15158\n",
      "Training Acc: 58.13, Training F1:0.68, Train Loss: 0.14345\n",
      "Epoch:3\n",
      "Validation Accuracy:57.26, Validation F1:0.73, Val Loss: 0.13965\n",
      "Training Acc: 60.16, Training F1:0.73, Train Loss: 0.12776\n",
      "Epoch:4\n",
      "Validation Accuracy:58.19, Validation F1:0.74, Val Loss: 0.13727\n",
      "Training Acc: 61.76, Training F1:0.75, Train Loss: 0.12008\n",
      "Epoch:5\n",
      "Validation Accuracy:59.02, Validation F1:0.75, Val Loss: 0.13025\n",
      "Training Acc: 63.33, Training F1:0.75, Train Loss: 0.10870\n",
      "Epoch:6\n",
      "Validation Accuracy:59.69, Validation F1:0.76, Val Loss: 0.12631\n",
      "Training Acc: 64.94, Training F1:0.76, Train Loss: 0.09765\n",
      "Epoch:7\n",
      "Validation Accuracy:59.98, Validation F1:0.77, Val Loss: 0.12204\n",
      "Training Acc: 65.75, Training F1:0.78, Train Loss: 0.08992\n",
      "Epoch:8\n",
      "Validation Accuracy:60.24, Validation F1:0.80, Val Loss: 0.11774\n",
      "Training Acc: 66.39, Training F1:0.80, Train Loss: 0.08021\n",
      "Epoch:9\n",
      "Validation Accuracy:60.82, Validation F1:0.73, Val Loss: 0.12096\n",
      "Training Acc: 67.52, Training F1:0.74, Train Loss: 0.07778\n",
      "Epoch:10\n",
      "Validation Accuracy:60.50, Validation F1:0.77, Val Loss: 0.11695\n",
      "Training Acc: 67.79, Training F1:0.78, Train Loss: 0.06814\n",
      "Epoch:11\n",
      "Validation Accuracy:60.68, Validation F1:0.78, Val Loss: 0.11338\n",
      "Training Acc: 68.21, Training F1:0.79, Train Loss: 0.06298\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:12\n",
      "Validation Accuracy:60.84, Validation F1:0.75, Val Loss: 0.11439\n",
      "Training Acc: 68.66, Training F1:0.77, Train Loss: 0.05935\n",
      "Epoch:13\n",
      "Validation Accuracy:60.86, Validation F1:0.75, Val Loss: 0.11162\n",
      "Training Acc: 68.86, Training F1:0.77, Train Loss: 0.05652\n",
      "Epoch:14\n",
      "Validation Accuracy:61.01, Validation F1:0.76, Val Loss: 0.11070\n",
      "Training Acc: 68.93, Training F1:0.78, Train Loss: 0.05498\n",
      "Epoch:15\n",
      "Validation Accuracy:60.76, Validation F1:0.75, Val Loss: 0.11269\n",
      "Training Acc: 68.93, Training F1:0.76, Train Loss: 0.05466\n",
      "Epoch:16\n",
      "Validation Accuracy:60.30, Validation F1:0.73, Val Loss: 0.11282\n",
      "Training Acc: 68.94, Training F1:0.75, Train Loss: 0.05391\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:17\n",
      "Validation Accuracy:60.68, Validation F1:0.75, Val Loss: 0.11028\n",
      "Training Acc: 69.02, Training F1:0.77, Train Loss: 0.05172\n",
      "Epoch:18\n",
      "Validation Accuracy:60.92, Validation F1:0.76, Val Loss: 0.11047\n",
      "Training Acc: 69.04, Training F1:0.77, Train Loss: 0.05223\n",
      "Epoch:19\n",
      "Validation Accuracy:60.55, Validation F1:0.75, Val Loss: 0.11069\n",
      "Training Acc: 69.01, Training F1:0.77, Train Loss: 0.05299\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:20\n",
      "Validation Accuracy:60.88, Validation F1:0.76, Val Loss: 0.10991\n",
      "Training Acc: 69.03, Training F1:0.78, Train Loss: 0.05104\n",
      "Epoch:21\n",
      "Validation Accuracy:60.78, Validation F1:0.76, Val Loss: 0.11054\n",
      "Training Acc: 69.01, Training F1:0.77, Train Loss: 0.05135\n",
      "Epoch:22\n",
      "Validation Accuracy:60.82, Validation F1:0.75, Val Loss: 0.11020\n",
      "Training Acc: 69.03, Training F1:0.77, Train Loss: 0.05114\n",
      "Epoch:23\n",
      "Validation Accuracy:60.71, Validation F1:0.75, Val Loss: 0.11058\n",
      "Training Acc: 69.00, Training F1:0.77, Train Loss: 0.05276\n",
      "Epoch:24\n",
      "Validation Accuracy:60.89, Validation F1:0.77, Val Loss: 0.10890\n",
      "Training Acc: 69.00, Training F1:0.78, Train Loss: 0.05078\n",
      "Epoch:25\n",
      "Validation Accuracy:60.59, Validation F1:0.76, Val Loss: 0.11078\n",
      "Training Acc: 69.05, Training F1:0.78, Train Loss: 0.05178\n",
      "Epoch:26\n",
      "Validation Accuracy:60.80, Validation F1:0.76, Val Loss: 0.10881\n",
      "Training Acc: 69.04, Training F1:0.78, Train Loss: 0.05049\n",
      "Epoch:27\n",
      "Validation Accuracy:60.62, Validation F1:0.75, Val Loss: 0.11115\n",
      "Training Acc: 69.04, Training F1:0.77, Train Loss: 0.05229\n",
      "Epoch:28\n",
      "Validation Accuracy:61.03, Validation F1:0.76, Val Loss: 0.10981\n",
      "Training Acc: 69.00, Training F1:0.78, Train Loss: 0.05101\n",
      "Epoch:29\n",
      "Validation Accuracy:60.82, Validation F1:0.76, Val Loss: 0.11002\n",
      "Training Acc: 68.94, Training F1:0.77, Train Loss: 0.05144\n",
      "Epoch:30\n",
      "Validation Accuracy:60.78, Validation F1:0.75, Val Loss: 0.10969\n",
      "Training Acc: 69.02, Training F1:0.77, Train Loss: 0.05168\n",
      "Epoch:31\n",
      "Validation Accuracy:60.68, Validation F1:0.75, Val Loss: 0.11093\n",
      "Training Acc: 69.03, Training F1:0.76, Train Loss: 0.05293\n",
      "Epoch:32\n",
      "Validation Accuracy:60.85, Validation F1:0.76, Val Loss: 0.10902\n",
      "Training Acc: 68.99, Training F1:0.78, Train Loss: 0.05130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:33\n",
      "Validation Accuracy:60.76, Validation F1:0.76, Val Loss: 0.11024\n",
      "Training Acc: 69.02, Training F1:0.77, Train Loss: 0.05137\n",
      "Epoch:34\n",
      "Validation Accuracy:60.82, Validation F1:0.76, Val Loss: 0.11019\n",
      "Training Acc: 69.01, Training F1:0.77, Train Loss: 0.05137\n",
      "Epoch:35\n",
      "Validation Accuracy:60.45, Validation F1:0.73, Val Loss: 0.11148\n",
      "Training Acc: 69.02, Training F1:0.75, Train Loss: 0.05156\n",
      "Epoch:36\n",
      "Validation Accuracy:60.65, Validation F1:0.74, Val Loss: 0.11121\n",
      "Training Acc: 69.02, Training F1:0.75, Train Loss: 0.05222\n",
      "Epoch:37\n",
      "Validation Accuracy:61.07, Validation F1:0.76, Val Loss: 0.10893\n",
      "Training Acc: 69.05, Training F1:0.78, Train Loss: 0.05006\n",
      "Epoch:38\n",
      "Validation Accuracy:60.79, Validation F1:0.75, Val Loss: 0.11046\n",
      "Training Acc: 68.99, Training F1:0.77, Train Loss: 0.05194\n",
      "Epoch:39\n",
      "Validation Accuracy:60.89, Validation F1:0.75, Val Loss: 0.11109\n",
      "Training Acc: 69.03, Training F1:0.76, Train Loss: 0.05199\n",
      "Epoch:40\n",
      "Validation Accuracy:60.96, Validation F1:0.76, Val Loss: 0.11073\n",
      "Training Acc: 69.03, Training F1:0.77, Train Loss: 0.05237\n",
      "Epoch:41\n",
      "Validation Accuracy:60.95, Validation F1:0.76, Val Loss: 0.10936\n",
      "Training Acc: 69.04, Training F1:0.77, Train Loss: 0.05158\n",
      "Epoch:42\n",
      "Validation Accuracy:60.74, Validation F1:0.74, Val Loss: 0.11141\n",
      "Training Acc: 69.03, Training F1:0.76, Train Loss: 0.05070\n",
      "Epoch:43\n",
      "Validation Accuracy:60.86, Validation F1:0.75, Val Loss: 0.11129\n",
      "Training Acc: 69.03, Training F1:0.77, Train Loss: 0.05240\n",
      "Epoch:44\n",
      "Validation Accuracy:60.88, Validation F1:0.76, Val Loss: 0.11060\n",
      "Training Acc: 69.05, Training F1:0.77, Train Loss: 0.05184\n",
      "Epoch:45\n",
      "Validation Accuracy:61.08, Validation F1:0.77, Val Loss: 0.10954\n",
      "Training Acc: 69.04, Training F1:0.78, Train Loss: 0.05167\n",
      "Epoch:46\n",
      "Validation Accuracy:61.12, Validation F1:0.75, Val Loss: 0.11164\n",
      "Training Acc: 69.05, Training F1:0.77, Train Loss: 0.05226\n",
      "Epoch:47\n",
      "Validation Accuracy:60.82, Validation F1:0.76, Val Loss: 0.11056\n",
      "Training Acc: 69.02, Training F1:0.77, Train Loss: 0.05216\n",
      "Epoch:48\n",
      "Validation Accuracy:61.03, Validation F1:0.77, Val Loss: 0.10961\n",
      "Training Acc: 69.05, Training F1:0.78, Train Loss: 0.05158\n",
      "Epoch:49\n",
      "Validation Accuracy:60.78, Validation F1:0.76, Val Loss: 0.10945\n",
      "Training Acc: 69.02, Training F1:0.78, Train Loss: 0.05183\n",
      "Epoch:50\n",
      "Validation Accuracy:60.55, Validation F1:0.74, Val Loss: 0.11193\n",
      "Training Acc: 69.06, Training F1:0.76, Train Loss: 0.05254\n",
      "Epoch:1\n",
      "Validation Accuracy:55.47, Validation F1:0.67, Val Loss: 0.15061\n",
      "Training Acc: 56.33, Training F1:0.67, Train Loss: 0.14792\n",
      "Epoch:2\n",
      "Validation Accuracy:58.32, Validation F1:0.74, Val Loss: 0.13591\n",
      "Training Acc: 59.72, Training F1:0.74, Train Loss: 0.13023\n",
      "Epoch:3\n",
      "Validation Accuracy:59.86, Validation F1:0.76, Val Loss: 0.12655\n",
      "Training Acc: 61.88, Training F1:0.76, Train Loss: 0.11764\n",
      "Epoch:4\n",
      "Validation Accuracy:60.91, Validation F1:0.78, Val Loss: 0.11776\n",
      "Training Acc: 63.97, Training F1:0.78, Train Loss: 0.10351\n",
      "Epoch:5\n",
      "Validation Accuracy:61.58, Validation F1:0.77, Val Loss: 0.11012\n",
      "Training Acc: 65.36, Training F1:0.78, Train Loss: 0.08845\n",
      "Epoch:6\n",
      "Validation Accuracy:62.06, Validation F1:0.79, Val Loss: 0.10593\n",
      "Training Acc: 66.35, Training F1:0.80, Train Loss: 0.07960\n",
      "Epoch:7\n",
      "Validation Accuracy:62.69, Validation F1:0.75, Val Loss: 0.10462\n",
      "Training Acc: 67.54, Training F1:0.76, Train Loss: 0.07629\n",
      "Epoch:8\n",
      "Validation Accuracy:62.89, Validation F1:0.79, Val Loss: 0.09670\n",
      "Training Acc: 68.13, Training F1:0.80, Train Loss: 0.06519\n",
      "Epoch:9\n",
      "Validation Accuracy:63.78, Validation F1:0.79, Val Loss: 0.09279\n",
      "Training Acc: 68.69, Training F1:0.80, Train Loss: 0.05947\n",
      "Epoch:10\n",
      "Validation Accuracy:63.71, Validation F1:0.79, Val Loss: 0.09270\n",
      "Training Acc: 69.07, Training F1:0.80, Train Loss: 0.05638\n",
      "Epoch:11\n",
      "Validation Accuracy:62.59, Validation F1:0.75, Val Loss: 0.09700\n",
      "Training Acc: 69.04, Training F1:0.76, Train Loss: 0.05784\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:12\n",
      "Validation Accuracy:63.42, Validation F1:0.77, Val Loss: 0.09210\n",
      "Training Acc: 69.19, Training F1:0.78, Train Loss: 0.05339\n",
      "Epoch:13\n",
      "Validation Accuracy:63.93, Validation F1:0.75, Val Loss: 0.08758\n",
      "Training Acc: 69.40, Training F1:0.77, Train Loss: 0.04964\n",
      "Epoch:14\n",
      "Validation Accuracy:63.92, Validation F1:0.76, Val Loss: 0.08662\n",
      "Training Acc: 69.43, Training F1:0.78, Train Loss: 0.04786\n",
      "Epoch:15\n",
      "Validation Accuracy:63.96, Validation F1:0.77, Val Loss: 0.08627\n",
      "Training Acc: 69.44, Training F1:0.78, Train Loss: 0.04709\n",
      "Epoch:16\n",
      "Validation Accuracy:64.10, Validation F1:0.77, Val Loss: 0.08526\n",
      "Training Acc: 69.44, Training F1:0.78, Train Loss: 0.04536\n",
      "Epoch:17\n",
      "Validation Accuracy:64.05, Validation F1:0.77, Val Loss: 0.08549\n",
      "Training Acc: 69.44, Training F1:0.78, Train Loss: 0.04509\n",
      "Epoch:18\n",
      "Validation Accuracy:64.12, Validation F1:0.78, Val Loss: 0.08496\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04526\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:19\n",
      "Validation Accuracy:64.06, Validation F1:0.77, Val Loss: 0.08436\n",
      "Training Acc: 69.45, Training F1:0.78, Train Loss: 0.04458\n",
      "Epoch:20\n",
      "Validation Accuracy:64.11, Validation F1:0.78, Val Loss: 0.08400\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04443\n",
      "Epoch:21\n",
      "Validation Accuracy:64.17, Validation F1:0.78, Val Loss: 0.08398\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04403\n",
      "Epoch:22\n",
      "Validation Accuracy:64.19, Validation F1:0.79, Val Loss: 0.08366\n",
      "Training Acc: 69.45, Training F1:0.80, Train Loss: 0.04397\n",
      "Epoch:23\n",
      "Validation Accuracy:64.05, Validation F1:0.77, Val Loss: 0.08480\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04451\n",
      "Epoch:24\n",
      "Validation Accuracy:64.22, Validation F1:0.79, Val Loss: 0.08419\n",
      "Training Acc: 69.45, Training F1:0.80, Train Loss: 0.04444\n",
      "Epoch:25\n",
      "Validation Accuracy:63.69, Validation F1:0.76, Val Loss: 0.08613\n",
      "Training Acc: 69.45, Training F1:0.77, Train Loss: 0.04501\n",
      "Epoch:26\n",
      "Validation Accuracy:64.13, Validation F1:0.78, Val Loss: 0.08392\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04405\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:27\n",
      "Validation Accuracy:63.90, Validation F1:0.77, Val Loss: 0.08476\n",
      "Training Acc: 69.45, Training F1:0.78, Train Loss: 0.04415\n",
      "Epoch:28\n",
      "Validation Accuracy:63.99, Validation F1:0.77, Val Loss: 0.08405\n",
      "Training Acc: 69.45, Training F1:0.78, Train Loss: 0.04395\n",
      "Epoch:29\n",
      "Validation Accuracy:64.15, Validation F1:0.78, Val Loss: 0.08419\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04405\n",
      "Epoch:30\n",
      "Validation Accuracy:63.92, Validation F1:0.77, Val Loss: 0.08492\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04451\n",
      "Epoch:31\n",
      "Validation Accuracy:64.11, Validation F1:0.78, Val Loss: 0.08415\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04442\n",
      "Epoch:32\n",
      "Validation Accuracy:63.94, Validation F1:0.77, Val Loss: 0.08485\n",
      "Training Acc: 69.45, Training F1:0.78, Train Loss: 0.04442\n",
      "Epoch:33\n",
      "Validation Accuracy:64.18, Validation F1:0.78, Val Loss: 0.08395\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04380\n",
      "Epoch:34\n",
      "Validation Accuracy:64.12, Validation F1:0.77, Val Loss: 0.08472\n",
      "Training Acc: 69.45, Training F1:0.78, Train Loss: 0.04464\n",
      "Epoch:35\n",
      "Validation Accuracy:63.88, Validation F1:0.77, Val Loss: 0.08509\n",
      "Training Acc: 69.45, Training F1:0.78, Train Loss: 0.04469\n",
      "Epoch:36\n",
      "Validation Accuracy:63.94, Validation F1:0.78, Val Loss: 0.08406\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04379\n",
      "Epoch:37\n",
      "Validation Accuracy:63.95, Validation F1:0.76, Val Loss: 0.08426\n",
      "Training Acc: 69.45, Training F1:0.78, Train Loss: 0.04371\n",
      "Epoch:38\n",
      "Validation Accuracy:64.10, Validation F1:0.78, Val Loss: 0.08408\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04358\n",
      "Epoch:39\n",
      "Validation Accuracy:63.90, Validation F1:0.76, Val Loss: 0.08507\n",
      "Training Acc: 69.45, Training F1:0.78, Train Loss: 0.04468\n",
      "Epoch:40\n",
      "Validation Accuracy:63.94, Validation F1:0.78, Val Loss: 0.08467\n",
      "Training Acc: 69.45, Training F1:0.80, Train Loss: 0.04423\n",
      "Epoch:41\n",
      "Validation Accuracy:63.77, Validation F1:0.77, Val Loss: 0.08450\n",
      "Training Acc: 69.45, Training F1:0.78, Train Loss: 0.04397\n",
      "Epoch:42\n",
      "Validation Accuracy:63.99, Validation F1:0.77, Val Loss: 0.08456\n",
      "Training Acc: 69.45, Training F1:0.78, Train Loss: 0.04463\n",
      "Epoch:43\n",
      "Validation Accuracy:64.27, Validation F1:0.78, Val Loss: 0.08382\n",
      "Training Acc: 69.45, Training F1:0.79, Train Loss: 0.04377\n"
     ]
    }
   ],
   "source": [
    "model1 = snet2_jigsaw(20).to(device)\n",
    "model = snet2_jigsaw(20).to(device)\n",
    "sizes = [10, 50, 250, 500, 1000]\n",
    "for i in range(len(sizes)):\n",
    "    idx_train = Model_Data[i]\n",
    "    Y_mask_train = Y_mask[idx_train]\n",
    "    label_train = Y_true[idx_train]\n",
    "    weights_train = np.sum(Y_mask_train, axis= 1)/20\n",
    "    new_weights_train = weights_train.reshape(-1,1)*Y_mask_train\n",
    "    Train_dataset = ArrowOfTime(root_dir, sample_key[idx_train], new_weights_train, label_train)\n",
    "    Train_loader = torch.utils.data.DataLoader(dataset = Train_dataset, \n",
    "                                                  batch_size = BATCH_SIZE,\n",
    "                                                  shuffle = True,\n",
    "                                              collate_fn = my_collate)\n",
    "\n",
    "    \n",
    "    model.load_state_dict(model1.state_dict())\n",
    "    learning_rate = 10**(-5)\n",
    "    num_epochs = 50 # number epoch to train\n",
    "\n",
    "    optimizer = torch.optim.Adam([param for param in model.parameters() if param.requires_grad == True], lr=learning_rate, weight_decay = 0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True, threshold=0.03,\n",
    "                                                           threshold_mode='abs', cooldown=0, min_lr=0, eps=1e-08)\n",
    "\n",
    "    train_acc_list, train_loss_list, val_acc_list, val_loss_list, best_model_state_dict = train_model(Train_loader, Val_loader, model, optimizer, scheduler, num_epochs)\n",
    "    results_dict[sizes[i]] = {\n",
    "        'train_acc_list':train_acc_list,\n",
    "        'train_loss_list': train_loss_list,\n",
    "        'val_acc_list': val_acc_list,\n",
    "        'val_loss_list': val_loss_list,\n",
    "        'best_model_state_dict': best_model_state_dict\n",
    "    }\n",
    "    pickle.dump(results_dict, open('Size_Exp_Random_Wt_Results_size_{}.pkl'.format(sizes[i]),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.\n",
    "std = 0.\n",
    "for images, _, _ in Train_loader:\n",
    "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "    images1 = images.reshape(batch_samples, images.size(1), -1)\n",
    "    mean += images1.mean(2).sum(0)\n",
    "    std += images1.std(2).sum(0)\n",
    "    \n",
    "mean /= len(Train_loader.dataset)\n",
    "std /= len(Train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-24.3633]) tensor([14.2659])\n"
     ]
    }
   ],
   "source": [
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = conv_net().to(device)\n",
    "model.load_state_dict(reqd_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results_dict, open('Size_Exp_Jigsaw_Wt_Results.pkl'.format(sizes[i]),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([10, 50, 250, 500])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18().to(device)\n",
    "alexnet = models.alexnet().to(device)\n",
    "vgg16 = models.vgg16().to(device)\n",
    "squeezenet = models.squeezenet1_0().to(device)\n",
    "densenet = models.densenet161().to(device)\n",
    "inception = models.inception_v3().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
