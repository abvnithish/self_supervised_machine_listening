{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "from torch.optim import *\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "random.seed(7)\n",
    "torch.cuda.manual_seed(7)\n",
    "torch.manual_seed(7)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(7)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/beegfs/bva212/openmic-2018'\n",
    "OPENMIC = np.load(os.path.join(DATA_ROOT, 'openmic-2018.npz'))\n",
    "X, Y_true, Y_mask, sample_key = OPENMIC['X'], OPENMIC['Y_true'], OPENMIC['Y_mask'], OPENMIC['sample_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data = Y_mask.shape[0]\n",
    "idx_train = np.random.choice(len_data, int(len_data*0.7), replace=False)\n",
    "remain_set = set(np.arange(len_data))-set(idx_train)\n",
    "idx_test = np.random.choice(list(remain_set), int(len_data*0.1), replace=False)\n",
    "idx_val = list(remain_set-set(idx_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mask_train = Y_mask[idx_train]\n",
    "Y_mask_val = Y_mask[idx_val]\n",
    "Y_mask_test = Y_mask[idx_test]\n",
    "\n",
    "label_train = Y_true[idx_train]\n",
    "label_val = Y_true[idx_val]\n",
    "label_test = Y_true[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_train = np.sum(Y_mask_train, axis= 1)/20\n",
    "new_weights_train = weights_train.reshape(-1,1)*Y_mask_train\n",
    "weights_val = np.sum(Y_mask_val, axis= 1)/20\n",
    "new_weights_val = weights_val.reshape(-1,1)*Y_mask_val\n",
    "weights_test = np.sum(Y_mask_test, axis= 1)/20\n",
    "new_weights_test = weights_test.reshape(-1,1)*Y_mask_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrowOfTime(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, files, weights, label):\n",
    "        self.weights = weights\n",
    "        self.device = device\n",
    "        self.root_dir = root_dir\n",
    "        self.files = files\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        logscalogram = (np.load(self.root_dir + self.files[idx]+'_cqt.npy') - -24.3633)/14.2659\n",
    "        len_cqt = logscalogram.shape[1]\n",
    "        rem = len_cqt % 3\n",
    "        logscalograms = np.split(logscalogram[:, :-rem], 3, axis = 1)\n",
    "        logscalograms = np.stack(logscalograms)\n",
    "        weight = self.weights[idx]\n",
    "        label = self.label[idx]\n",
    "        return {'logscalogram': logscalograms, 'label': label[np.newaxis, :], 'weight': weight[np.newaxis, :]}\n",
    "\n",
    "filenames = []\n",
    "root_dir = '/beegfs/bva212/openmic-2018/cqt_full/'\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def my_collate(batch):\n",
    "    data = np.stack([item['logscalogram'] for item in batch])\n",
    "    target = np.concatenate([item['label'] for item in batch],axis=0)\n",
    "    weight = np.concatenate([item['weight'] for item in batch],axis=0)\n",
    "    return [torch.from_numpy(data).float(), torch.from_numpy(target).float(), torch.from_numpy(weight).float()]\n",
    "\n",
    "Train_dataset = ArrowOfTime(root_dir, sample_key[idx_train], new_weights_train, label_train)\n",
    "Train_loader = torch.utils.data.DataLoader(dataset = Train_dataset, \n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              shuffle = True,\n",
    "                                          collate_fn = my_collate)\n",
    "\n",
    "Val_dataset = ArrowOfTime(root_dir, sample_key[idx_val], new_weights_val, label_val)\n",
    "Val_loader = torch.utils.data.DataLoader(dataset = Val_dataset, \n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              shuffle = True,\n",
    "                                        collate_fn = my_collate)\n",
    "\n",
    "Test_dataset = ArrowOfTime(root_dir, sample_key[idx_test], new_weights_test, label_test)\n",
    "Test_loader = torch.utils.data.DataLoader(dataset = Test_dataset, \n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              shuffle = True,\n",
    "                                        collate_fn = my_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n",
      "Validation Accuracy:52.70, Validation F1:0.69, Val Loss: 0.15826\n",
      "Training Acc: 53.53, Training F1:0.69, Train Loss: 0.15249\n",
      "Epoch:2\n",
      "Validation Accuracy:54.95, Validation F1:0.72, Val Loss: 0.14763\n",
      "Training Acc: 56.61, Training F1:0.72, Train Loss: 0.13993\n",
      "Epoch:3\n",
      "Validation Accuracy:56.58, Validation F1:0.77, Val Loss: 0.13998\n",
      "Training Acc: 57.95, Training F1:0.77, Train Loss: 0.12930\n",
      "Epoch:4\n",
      "Validation Accuracy:56.59, Validation F1:0.78, Val Loss: 0.13707\n",
      "Training Acc: 58.62, Training F1:0.78, Train Loss: 0.12526\n",
      "Epoch:5\n",
      "Validation Accuracy:57.35, Validation F1:0.80, Val Loss: 0.13558\n",
      "Training Acc: 60.15, Training F1:0.80, Train Loss: 0.11757\n",
      "Epoch:6\n",
      "Validation Accuracy:58.11, Validation F1:0.79, Val Loss: 0.13261\n",
      "Training Acc: 61.37, Training F1:0.79, Train Loss: 0.10943\n",
      "Epoch:7\n",
      "Validation Accuracy:57.80, Validation F1:0.83, Val Loss: 0.13242\n",
      "Training Acc: 61.96, Training F1:0.83, Train Loss: 0.10172\n",
      "Epoch:8\n",
      "Validation Accuracy:57.27, Validation F1:0.82, Val Loss: 0.13421\n",
      "Training Acc: 62.60, Training F1:0.83, Train Loss: 0.09750\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:9\n",
      "Validation Accuracy:57.41, Validation F1:0.76, Val Loss: 0.13656\n",
      "Training Acc: 64.18, Training F1:0.77, Train Loss: 0.09668\n",
      "Epoch:10\n",
      "Validation Accuracy:57.90, Validation F1:0.82, Val Loss: 0.13183\n",
      "Training Acc: 65.42, Training F1:0.82, Train Loss: 0.08286\n",
      "Epoch:11\n",
      "Validation Accuracy:57.80, Validation F1:0.80, Val Loss: 0.13384\n",
      "Training Acc: 65.26, Training F1:0.81, Train Loss: 0.08283\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:12\n",
      "Validation Accuracy:58.08, Validation F1:0.80, Val Loss: 0.13429\n",
      "Training Acc: 66.64, Training F1:0.81, Train Loss: 0.07726\n",
      "Epoch:13\n",
      "Validation Accuracy:57.69, Validation F1:0.81, Val Loss: 0.13315\n",
      "Training Acc: 66.18, Training F1:0.81, Train Loss: 0.07761\n",
      "Epoch:14\n",
      "Validation Accuracy:57.06, Validation F1:0.80, Val Loss: 0.13598\n",
      "Training Acc: 65.43, Training F1:0.81, Train Loss: 0.08015\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:15\n",
      "Validation Accuracy:57.78, Validation F1:0.80, Val Loss: 0.13348\n",
      "Training Acc: 66.53, Training F1:0.81, Train Loss: 0.07512\n",
      "Epoch:16\n",
      "Validation Accuracy:57.56, Validation F1:0.81, Val Loss: 0.13400\n",
      "Training Acc: 66.00, Training F1:0.82, Train Loss: 0.07681\n",
      "Epoch:17\n",
      "Validation Accuracy:57.96, Validation F1:0.81, Val Loss: 0.13413\n",
      "Training Acc: 66.64, Training F1:0.81, Train Loss: 0.07661\n",
      "Epoch:18\n",
      "Validation Accuracy:57.65, Validation F1:0.81, Val Loss: 0.13465\n",
      "Training Acc: 66.15, Training F1:0.81, Train Loss: 0.07775\n",
      "Epoch:19\n",
      "Validation Accuracy:57.53, Validation F1:0.80, Val Loss: 0.13489\n",
      "Training Acc: 66.43, Training F1:0.81, Train Loss: 0.07940\n",
      "Epoch:20\n",
      "Validation Accuracy:57.49, Validation F1:0.81, Val Loss: 0.13522\n",
      "Training Acc: 65.98, Training F1:0.82, Train Loss: 0.07626\n",
      "Epoch:21\n",
      "Validation Accuracy:57.80, Validation F1:0.81, Val Loss: 0.13548\n",
      "Training Acc: 66.47, Training F1:0.81, Train Loss: 0.07656\n",
      "Epoch:22\n",
      "Validation Accuracy:57.52, Validation F1:0.81, Val Loss: 0.13454\n",
      "Training Acc: 66.37, Training F1:0.82, Train Loss: 0.07763\n",
      "Epoch:23\n",
      "Validation Accuracy:57.94, Validation F1:0.81, Val Loss: 0.13473\n",
      "Training Acc: 66.34, Training F1:0.82, Train Loss: 0.07849\n",
      "Epoch:24\n",
      "Validation Accuracy:57.55, Validation F1:0.81, Val Loss: 0.13419\n",
      "Training Acc: 66.44, Training F1:0.82, Train Loss: 0.07708\n",
      "Epoch:25\n",
      "Validation Accuracy:57.59, Validation F1:0.81, Val Loss: 0.13470\n",
      "Training Acc: 66.51, Training F1:0.82, Train Loss: 0.07496\n",
      "Epoch:26\n",
      "Validation Accuracy:57.97, Validation F1:0.82, Val Loss: 0.13367\n",
      "Training Acc: 66.17, Training F1:0.82, Train Loss: 0.07649\n",
      "Epoch:27\n",
      "Validation Accuracy:58.05, Validation F1:0.81, Val Loss: 0.13389\n",
      "Training Acc: 66.49, Training F1:0.82, Train Loss: 0.07689\n",
      "Epoch:28\n",
      "Validation Accuracy:57.44, Validation F1:0.81, Val Loss: 0.13539\n",
      "Training Acc: 66.23, Training F1:0.81, Train Loss: 0.07700\n",
      "Epoch:29\n",
      "Validation Accuracy:57.46, Validation F1:0.81, Val Loss: 0.13464\n",
      "Training Acc: 66.49, Training F1:0.81, Train Loss: 0.07794\n"
     ]
    }
   ],
   "source": [
    "class snet2_jigsaw(nn.Module):\n",
    "\n",
    "    def __init__(self, output_classes = 20):\n",
    "        '''\n",
    "        Create the 5 Conv Layer Sound Net network architecture as per the paper - https://arxiv.org/pdf/1610.09001.pdf\n",
    "        '''\n",
    "        super(snet2_jigsaw, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(nn.Conv2d(in_channels = 1, out_channels= 16, kernel_size = 5, stride = 2, padding = 5), \n",
    "                                nn.BatchNorm2d(num_features = 16), \n",
    "                                nn.ReLU(inplace = True),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5, stride = 2, padding = 5),\n",
    "                                nn.BatchNorm2d(32),\n",
    "                                nn.ReLU(inplace = True),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5, padding = 5),\n",
    "                                nn.BatchNorm2d(64),\n",
    "                                nn.ReLU(inplace = True),\n",
    "                                nn.AvgPool2d(kernel_size = 3),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 4, padding = 4),\n",
    "                                nn.BatchNorm2d(128),\n",
    "                                nn.ReLU(inplace = True),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 4, padding = 4),\n",
    "                                nn.BatchNorm2d(256),\n",
    "                                nn.ReLU(inplace = True),\n",
    "                                nn.AvgPool2d(kernel_size = 3),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 2, padding = 3),\n",
    "                                nn.BatchNorm2d(512),\n",
    "                                nn.ReLU(inplace = True),\n",
    "\n",
    "                                nn.Conv2d(in_channels = 512, out_channels = 1024, kernel_size = 3, stride = 2, padding = 3),\n",
    "                                nn.BatchNorm2d(1024),\n",
    "                                nn.ReLU(inplace = True),\n",
    "                                nn.AdaptiveAvgPool2d(output_size = 1)\n",
    "                                )\n",
    "        self.concat_mlp_layer = nn.Sequential(nn.Linear(3072, 2048),\n",
    "                                              nn.BatchNorm1d(num_features = 2048), \n",
    "                                              nn.ReLU(inplace = True),\n",
    "                                              \n",
    "                                              nn.Linear(2048, 1024),\n",
    "                                              nn.BatchNorm1d(num_features = 1024), \n",
    "                                              nn.ReLU(inplace = True),\n",
    "                                              \n",
    "                                              nn.Linear(1024, 256),\n",
    "                                              nn.BatchNorm1d(num_features = 256), \n",
    "                                              nn.ReLU(inplace = True),\n",
    "                                             )\n",
    "        self.mlp_layer = nn.Linear(256, output_classes)\n",
    "              \n",
    "    def forward(self, input):\n",
    "        conv_strips = []\n",
    "        n_strips = input.shape[1]\n",
    "        for strip in range(n_strips):\n",
    "            conv_strip = input[:,strip]\n",
    "            conv_strip = conv_strip.unsqueeze(1)\n",
    "            conv_strips.append(self.conv_layers(conv_strip))\n",
    "\n",
    "        concat_out=torch.cat(conv_strips,1)\n",
    "        out = self.concat_mlp_layer(concat_out.view(concat_out.shape[0], -1))\n",
    "        output = self.mlp_layer(out.view(out.shape[0], -1))\n",
    "        return output\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "        \n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    total_num = 0\n",
    "    actual_arr = []\n",
    "    predicted_arr = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for spectrogram, target, weight in loader:\n",
    "            spectrogram_batch, target_batch, weight_batch = spectrogram.to(device), target.to(device), weight.to(device)\n",
    "            outputs = model(spectrogram_batch)\n",
    "            loss = F.binary_cross_entropy_with_logits(outputs, target_batch,\n",
    "                                                  weight = weight_batch,\n",
    "                                                  reduction='sum')\n",
    "            predicted = (torch.sigmoid(outputs.data)>0.5).float()\n",
    "            \n",
    "            actual_arr.extend(target.view(1,-1).squeeze().numpy().astype(int).tolist())\n",
    "            predicted_arr.extend(predicted.view(1,-1).squeeze().cpu().numpy().astype(int).tolist())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total += weight_batch.shape[0]\n",
    "            \n",
    "            correct += ((weight_batch != 0).float()*(predicted.eq(target_batch.view_as(predicted)).float())).sum().item()\n",
    "            total_num += (weight_batch != 0).sum().item()\n",
    "        accuracy = (100 * correct / total_num)\n",
    "    return accuracy, f1_score(actual_arr, predicted_arr, average='micro'), total_loss/total\n",
    "\n",
    "def train_model(train_loader, val_loader, model, optimizer, scheduler, num_epochs):\n",
    "    train_acc_list = []\n",
    "    train_loss_list = []\n",
    "    val_acc_list = []\n",
    "    val_loss_list = []\n",
    "    train_f1_list = []\n",
    "    val_f1_list = []\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for spectrogram, target, weight in train_loader:\n",
    "            model.train()\n",
    "            spectrogram_batch, target_batch, weight_batch = spectrogram.to(device), target.to(device), weight.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(spectrogram_batch)\n",
    "            loss = F.binary_cross_entropy_with_logits(outputs, target_batch,\n",
    "                                                  weight = weight_batch,\n",
    "                                                  reduction='sum')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_acc, f1_score_train, train_loss = test_model(train_loader, model)\n",
    "        val_acc, f1_score_val, val_loss = test_model(val_loader, model)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state_dict = deepcopy(model.state_dict())\n",
    "        \n",
    "        train_acc_list.append(train_acc)\n",
    "        train_f1_list.append(f1_score_train)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_f1_list.append(f1_score_val)\n",
    "        val_acc_list.append(val_acc)\n",
    "        val_loss_list.append(val_loss)\n",
    "        \n",
    "        scheduler.step(val_acc)\n",
    "        print(\"Epoch:{}\".format(epoch+1))\n",
    "        print(\"Validation Accuracy:{:.2f}, Validation F1:{:.2f}, Val Loss: {:.5f}\".format(val_acc, f1_score_val, val_loss))\n",
    "        print(\"Training Acc: {:.2f}, Training F1:{:.2f}, Train Loss: {:.5f}\".format(train_acc, f1_score_train, train_loss))\n",
    "    return train_acc_list, train_loss_list, val_acc_list, val_loss_list, best_model_state_dict\n",
    "\n",
    "weights = torch.load('/beegfs/sc6957/capstone/models/20191116/snet2_jigsaw_large_best_model.pth')['modelStateDict']\n",
    "model = snet2_jigsaw(2)\n",
    "model.load_state_dict(weights)\n",
    "model.mlp_layer = nn.Linear(256, 20)\n",
    "model.to(device)\n",
    "learning_rate = 10**(-5)\n",
    "num_epochs = 50 # number epoch to train\n",
    "\n",
    "optimizer = torch.optim.Adam([param for param in model.parameters() if param.requires_grad == True], lr=learning_rate, weight_decay = 10**(-2))\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True, threshold=0.03,\n",
    "                                                       threshold_mode='abs', cooldown=0, min_lr=0, eps=1e-08)\n",
    "\n",
    "train_acc_list, train_loss_list, val_acc_list, val_loss_list, best_model_state_dict = train_model(Train_loader, Val_loader, model, optimizer, scheduler, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.\n",
    "std = 0.\n",
    "for images, _, _ in Train_loader:\n",
    "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "    images1 = images.reshape(batch_samples, images.size(1), -1)\n",
    "    mean += images1.mean(2).sum(0)\n",
    "    std += images1.std(2).sum(0)\n",
    "    \n",
    "mean /= len(Train_loader.dataset)\n",
    "std /= len(Train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-24.3633]) tensor([14.2659])\n"
     ]
    }
   ],
   "source": [
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
